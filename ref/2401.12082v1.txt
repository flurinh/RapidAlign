Matching biomolecular structures by registration of
point clouds
Michael Habeck 1,2∗, Andreas Kr¨ opelin 1, and Nima Vakili 1,2
January 23, 2024
1Microscopic Image Analysis Group, Jena University Hospital, 07743 Jena, Germany
2Max Planck Institute for Multidisciplinary Sciences, 37077 G¨ ottingen, Germany
*E-Mail: michael.habeck@uni-jena.de
Abstract
Motivation: Assessing the match between two biomolecular structures is at the heart
of structural analyses such as superposition, alignment and docking. These tasks are
typically solved with specialized structure-matching techniques implemented in software
for protein structural alignment, rigid-body docking, or rigid fitting into cryo-EM maps.
Results: We present a unifying framework to compare biomolecular structures by applying
ideas from computer vision. The structures are represented as three-dimensional
point clouds and compared by quantifying their overlap. We use the kernel correlation
to measure point cloud overlap, and discuss local and global optimization strategies for
maximizing the kernel correlation over the space of rigid transformations. We derive a
majorization-minimization procedure that can be used to register two point clouds without
establishing a point-to-point correspondence. We demonstrate that the majorizationminimization
algorithms outperform the commonly used Iterative Closest Point registration
algorithm. Furthermore, we discuss and benchmark a a randomization strategy for
globally optimizing the kernel correlation. We illustrate the approach on various 3D fitting
problems such as the comparison of circularly permuted structures and rigid fitting of
cryo-EM maps or bead models from small-angle scattering.
1 arXiv:2401.12082v1 [
q-bio.BM] 22 Jan 2024
1 Introduction
Superposition and comparison of biomolecular structures are common tasks in structural
biology. Structures are compared and aligned to predict the conformation and function of
proteins, for example by homology modeling. To assess the conformational diversity of
structures revealed by NMR or other structure determination methods, multiple conformations
need to be superimposed in a meaningful fashion. Rigid docking approaches optimize
the match between an experimental shape revealed by cryo-electron microscopy
or solution scattering with a known structure.
Aside from manual superposition approaches requiring user intervention, the standard
approach to superimpose and compare different conformations of the same biomolecule
is to minimize their root-mean-square deviation (RMSD). To compute the RMSD,
six rigid degrees of freedom are determined by a singular value decomposition (Kabsch,
1976). This assumes a least-squares criterion for assessing the match between two
structures.
Robust variants of the RMSD take account of the fact that the RMSD will be less
meaningful if the structures undergo large conformational changes (Hirsch and Habeck,
2008; Mechelke and Habeck, 2010) or show varying degrees of structural heterogeneity
(Theobald and Wuttke, 2006). Variants of the standard least-squares superposition such
as the weighted RMSD (Damm and Carlson, 2006) have been proposed to tackle more
challenging superposition tasks.
Optimization of the (weighted) RMSD is feasible by extending the Kabsch algorithm,
but restricted to cases where the correspondence between the positions in both structures
is known. This requirement holds, for example, for NMR ensembles. In the more
general case, the correspondence between positions in both structures is unknown. Both
problems, 3D superposition and establishing a correspondence between equivalent positions,
are intertwined and cannot be solved independently of each other.
This situation occurs in protein structural alignment where we need to solve two
problems: First, we need to establish the correspondence between evolutionarily related
amino acids. Second, we must find the best superposition of corresponding threedimensional
coordinates such that related amino acids are close in space. However,
the approach is restricted to situations where the correspondence is consistent with the
sequential order of the amino acids (such that dynamic programming can be used to
solve the alignment problem). But there are cases where standard structural alignment
of evolutionarily related proteins does not apply any more such as, for example, circular
permutation,
When working with reconstructions from cryo-electron microscopy (cryo-EM), we might
want to dock a high-resolution structure into a 3D density map (Villa and Lasker, 2014).
Rigid docking could either use a voxel-based representation of both structures or particle
models such as an atomic structure or a bead model. In the first case, the high-resolution
structure needs to be converted to a density map. In the second case, the density map
2
has to be converted to a (pseudo)-atomic structure. Kawabata (2008) introduced a decomposition
of cryo-EM density maps into a mixture of anisotropic Gaussians that are
characterized by a center position, a weight and a covariance matrix (representing an
ellipsoidal shape). Omokage search (Suzuki et al., 2016) uses this representation to
rapidly compare the overall shape of two or more structures obtained with X-ray crystallography,
cryo-EM or small-angle scattering (SAS).
Here, we solve all of the mentioned comparison and superposition tasks within a
common framework. We use a particle-based representation of biomolecular structures
including atomic structures, cryo-EM density maps, and bead models from SAS. To compare
two biomolecular structures, we use the kernel correlation which has been introduced
in computer vision to register point clouds. We discuss local and global strategies
to optimize the kernel correlation over rigid transformations of one structure against the
other structure. Finally, we illustrate our approach on various comparison and superposition
tasks.
2 Methods
2.1 Representation of biomolecular structures by weighted
point clouds
We use weighted point clouds to represent biomolecular structures from different experimental
sources. A weighted point cloud comprises a collection of I points at positions xi
and with associated weights pi . The positions can be stored in an I × 3 matrix X whose
rows are the 3D coordinates of the points, the weights form an I-dimensional vector p.
Atomic structures (Berman et al., 2000) can naturally be viewed as point clouds where
alpha carbons often serve as representative atoms and weights could be constant or
proportional to the mass or occupancy. In case of large structures such as multi-domain
proteins or macromolecular complexes, coarse graining allows us to reduce the size of
the point cloud such that a single point represents multiple atoms.
Cryo-EM structures are typically represented as gridded 3D volumes. Structural manipulations
such as a rigid transformation necessitate the interpolation of voxels values,
which is slow and prone to artifacts. We therefore prefer to also represent volumetric
data as weighted point clouds (Vakili and Habeck, 2021). A powerful algorithm to
obtain weighted point clouds from large atomic structures and cryo-EM maps is DPmeans
(Kulis and Jordan, 2012), a non-parametric version of the K-means algorithm. In
DP-means, the radius of the bead is chosen by the user and the number of points is
estimated automatically.
3
2.2 Assessing the match between two point clouds by the
kernel correlation
Let us now compare two point clouds (X,q) and (Y,p) of size I and J, respectively. Both
clouds are typically represented in different frames of reference, and we need to rigidly
transform one cloud, the source, against the other, the target, in order to compare them
meaningfully. This is a common task in computer vison called rigid registration. A rigid
transformation involves a 3×3 rotation matrix R and translation vector t. To find the best
pose (R, t), we must optimize a quantitative measure of how well two point clouds match.
The kernel correlation (KC) κ (Tsin and Kanade, 2004)
κ(R, t) =
XI
i=1
XJ
j=1
qi pj ϕ(∥xi −Ryj −t∥) = qTΦ(R, t)p (1)
is such a measure where ϕ is a suitable kernel, ∥ · ∥ the Euclidean norm and Φ the I × J
kernel matrix with elements ϕij = ϕ(∥xi−Ryj−t∥). Here, the weighted point cloud (X,q) is
the fixed target, whereas (Y,p) is the movable source. KC is invariant under permutation
of the point indices, and does not require a correspondence between the points in both
clouds. This is convenient because optimization of KC will align two structures without
knowing or assuming a point-to-point correspondence.
Throughout this paper, we use the Gaussian radial basis function (RBF) kernel
ϕσ(r ) =
1
(2πσ2)3/2 exp

− 1
2σ2 r 2

(2)
where the bandwidth σ > 0 determines how tolerant KC is against mismatches. The
correlation of two Gaussian kernels is
⟨ϕσ1 (∥ · −μ1∥), ϕσ2 (∥ · −μ2∥)⟩ = ϕσ(∥μ1 −μ2∥) (3)
where ⟨q, p⟩ =
R
q(x)p(x)dx denotes the functional inner product; the variances satisfy
σ2 = σ2
1 + σ2
2. Due to the self-reproducing property of the Gaussian kernel (Eq. 3), KC
can be viewed as the inner product
κ(R, t) =
D
qσ1 , pσ2
􀀀
RT ( · −t)
E
(4)
of kernel density estimates (KDEs)
qσ(x) =
XI
i=1
qi ϕσ(∥x −xi∥), pσ(x) =
XJ
j=1
pj ϕσ(∥x −yj∥) (5)
whose variances satisfy σ2 = σ2
1 + σ2
2. By maximizing KC (Eq. 1), we minimize the
squared distance between the KDEs (Eq. 5).
The Kpax algorithm by Ritchie (2016) uses a related match criterion for protein structure
alignment. The major difference is that Kpax’s objective function is not the total sum
over all elements of the kernel matrix as in Eq. (1), but reduced to the aligned point pairs.
For general point cloud comparison, establishing an alignment is no longer suitable (think
of circularly permuted protein structures or cryo-EM maps).
4
An important parameter is the bandwidth σ. The smaller σ the rougher and more
difficult to optimize will be KC. On the other hand, large σ will result in ambiguous registrations.
Larger values of σ are more suitable for global registration, whereas a small
σ allows us to find locally similar subsets of points in both clouds. In principle, σ is a
free parameter that can be chosen by the user or by methods used in kernel density
estimation. In our applications, we exploit the fact that we are comparing biomolecular
structures and therefore can use our domain knowledge to fix reasonable σ values. For
example, when working with cryo-EM maps, the resolution of the map gives an estimate
for the appropriate σ. For the comparison of alpha carbon clouds derived from atomic
structures, we typically use σ = 5A˚ ≈
√
2×3.5A˚ where 3.5 A˚ is roughly the average distance
between alpha carbons. Ritchie (2016) uses a smaller bandwidth, σ =
√
2 × 1.4A˚
for aligning protein structures.
2.3 Fast evaluation of the kernel correlation
The evaluation of KC (Eq. 1) scales with IJ, which impedes systematic searches for
the globally optimal pose. However, restricting the Gaussian kernel to a finite support
can result in significant speed-ups. We typically use a 3σ cutoff: ϕσ(r ) = 0 for r > 3σ.
As a consequence, the double-sum in the evaluation of KC (Eq. 1) can be restricted to
a sum over contributions from points in a finite neighborhood. Efficient data structures
for spatial queries such as k-d trees, ball trees or neighbor lists can be used to rapidly
determine nearest neighbors or contacts below the cutoff distance. This allows us to
compute accurate approximations of KC in a fraction of time.
Grid-based techniques can produce further speed-ups. KC can be seen as the inner
product of a blurry target density qσ (Eq. 5) and a sharp source density p0(x) =
PJj
=1 pj δ(∥x − yj∥) where δ(·) denotes the Dirac delta function. Therefore, we can approximate
KC by a vector inner product over a grid G of 3D positions:
κ(R, t) =
D
qσ, p0
􀀀
RT ( · −t)
E
≈
X
x∈G
qσ(x) p0
􀀀
RT (x −t)

. (6)
We use a cubic rectilinear grid G to discretize the inner product. The vector {qσ(x)}x∈G
needs to be computed only once in a search over multiple rotations and translations. The
vector representing the source in pose (R, t) is obtained by subtracting the grid origin
from the transformed points Ryj +t, followed by a division of the shifted points by the grid
spacing and subsequent rounding. This results in a one to three orders of magnitude
faster computation of the kernel correlation. A comparison of the computation times
achieved with these implementations of the kernel correlation is shown in Supplementary
Figure S1.
5
2.4 Local optimization of the kernel correlation by iterative
majorization-minimization (MM)
Minimization of −log κ is equivalent to maximizing KC and produces an optimal rigid
registration of two point clouds. This is a non-convex optimization problem with many
local minima corresponding to partial matches of both point clouds. To optimize the
scoring function −log κ, we construct an upper bound that can be minimized in closed
form:
−log κ(R, t) = −log
X
ij
qi pj ϕσ(∥xi −Ryj −t∥)
≤ −
X
ij
qi pj wij log
ϕσ(∥xi −Ryj −t∥)
wij
=
1
2σ2
X
ij
qipjwij∥xi −Ryj −t∥2 + const
where we used Jensen’s inequality. The constant,
P
ij qipjwij logwij , does not depend
on the parameters of the rigid transformation. The inequality is valid for all weights wij
satisfying wij ≥ 0 and
P
ij qipjwij = 1. For weights proportional to the kernel matrix,
wij ∝ ϕσ(∥xi − Ryj − t∥), the upper bound touches −log κ at (R, t), and the inequality
becomes an identity.
This suggests a majorization-minimization (MM) strategy (Hunter and Lange, 2004)
to optimize KC by cycling between updates of wij followed by minimization of the upper
bound
u(R, t) =
1
2σ2
X
ij
qipjwij∥xi −Ryj −t∥2 . (7)
The solution of argmin u(R, t) is available in closed form (see supplementary information).
The optimal translation is
ˆt = x − ˆRRRˆRy (8)
with centers of mass x =
P
ij qipjwijxi and y =
P
ij qipjwijyj . The optimal rotation can be
computed by solving the matrix nearness problem
RRRˆRRRˆRR =
argmin
R ∈SO(3)
∥R −S∥2
F (9)
where S =
P
ij qipjw(n)
ij (xi − x)(yj − y)T and ∥ · ∥F is the Frobenius norm. Minimization
problem (9) can be solved by singular value decomposition of the 3×3 matrix S (Higham,
1989).
The following iterative MM procedure minimizes the negative logarithm of the kernel
correlation:
• Initialization: Generate a random pose (R, t) (alternatively, we can try to find a good
initial pose by some heuristic).
• Iterate until convergence (e.g. when changes in −log κ are no longer significant) or
until a maximum number of iterations has been reached:
6
0 1 2 3 4 5
RMSD [Å]
0
25
50
75
100
-recall [%]
6JC2
MM
DAMM
ICP
0 1 2 3 4 5
RMSD [Å]
6HF2
0 1 2 3 4 5
RMSD [Å]
1OEL
0 1 2 3 4 5
RMSD [Å]
5G5D
0 1 2 3 4 5
RMSD [Å]
6R4S
Figure 1: Testing local optimization strategies on various self-matching problems. A PDB
structure (indicated in panel titles) is fitted against a permuted and randomly transformed
version of itself. The performance is evaluated in terms of the α-recall, which is the percentage
of tests for which a given method achieves an RMSD below α.
1. Evaluate the kernel matrix ϕij = ϕσ(∥xi −Ryj −t∥) at the current pose (R, t) and
compute the normalized weights wij = ϕij/
P
i′j′ qi′pj′ϕi′j′ = ϕij/κ(R, t).
2. Minimize the upper bound u(R, t) by calculating the optimal rotation ˆR
RRˆR and
translation ˆt according to equations (9) and (8).
Supplementary Figure S2 illustrates the MM iterations for a specific example. It is also
possible to implement the MM updates when using a grid approximation of the kernel
correlation (Eq. 6); see the supplementary information for details.
2.5 Deterministic annealing
Choosing the kernel width σ should not be seen as a burden, but as a means to incorporate
prior knowledge and control the shape of the objective function −log κ. One of
the most widely used methods for rigid registration is the Iterative Closest Point (ICP)
algorithm (Besl and McKay, 1992; Chen and Medioni, 1992). Like our MM approach,
ICP iterates over two elementary steps: First, ICP establishes a correspondence between
points in X and Y by matching pairs whose distance ∥xi − Ryj − t∥ is minimal.
Second, the least-squares fitting problem is solved for all pairs of corresponding points.
However, ICP lacks a bandwidth parameter, its only algorithmic parameter is the number
of iterations.
In the KC approach, we can use the bandwidth σ to gradually change the objective
function. Because MM is only a local search strategy, it will strongly depend on the initial
pose, which also holds for ICP. To avoid getting trapped in the nearest pose, we propose
a simple modification reminiscent of deterministic annealing (Rose et al., 1990). During
iterative MM, we decrease the kernel bandwidth gradually until we reach the desired σ
value. The bandwidth is analogous to a temperature: Large σ values (high temperatures)
result in a flat cost function with shallow minima, annealing (reduction of σ) makes the
cost function rougher, but also more selective. In our tests, we chose a simple linear
annealing schedule starting at a large σmax (typically 15 A˚ or more generally 5σ) and
7
decrease the kernel bandwidth by a constant increment in each iteration. Obviously there
are more options for the initial bandwidth and the progression of annealing. We found
that the simple linear temperature schedule is sufficient for the registration problems
considered in this article. We will use the abbreviation DAMM to denote the combination
of iterative majorization-minimization and deterministic annealing.
3 Results
We first report tests on local and global optimization strategies and then apply point cloud
registration techniques to various structure comparison and fitting tasks.
3.1 Performance of local registration methods on a selfmatching
benchmark
The following structure matching task sheds some light on the strengths and shortcomings
of the local optimization techniques detailed in Methods: A PDB structure is converted
to a point cloud of alpha carbon positions with weight one. This point cloud serves
as target against which a modified version of the same point cloud is matched. To generate
the source point cloud, we apply a random permutation and rigid transformation to
the target. Since the kernel correlation is invariant under permutation of the point indices,
the optimal rigid registration will produce the same kernel correlation that is achieved by
matching the target against itself:
P
ij ϕσ(∥xi−xj∥). We set σ = 5 A˚ and run self-matching
tests on structures with PDB codes 6JC2 (212), 6HF2 (325), 1OEL (524), 5G5D (160),
6R4S (382), where the numbers in brackets indicate the number of carbon alpha positions.
We test the local registration techniques, i.e. the MM algorithm (subsection 2.4) and
its annealed version DAMM (subsection 2.5), and compare them to ICP. For each structure,
we generate 1000 self-matching problems by randomly shuffling the positions of
the target and transforming them by a random rotation and translation. Ten random initial
poses are generated from which each of the local optimization methods (MM, DAMM,
and ICP) starts and runs for 50 iterations. The success of the registration method is
assesed by computing the root mean square deviation (RMSD) between corresponding
points in the target and transformed source. For a given pose (R, t), the RMSD is defined
as
RMSD =
vuut
1
I
XI
i=1
min
1≤j≤J
{∥xi −Ryj −t∥2} (10)
For the self-matching tasks, the optimal RMSD is zero. The error defined in Eq. (10) is
the objective function of the ICP algorithm.
Figure 1 shows the performance of the local registration methods on the self-matching
benchmark. We use the α-recall of the RMSD defined in Eq. (10) to assess the performance
(Zhou et al., 2016). The α-recall is the fraction of tests on which a registration
8
Figure 2: Radius of convergence of the local registration methods. The TIM barrel structure
6HF2 was matched against itself starting from initial rotations that form a tessellation of
rotation space at a very fine level of discretization. The distance between the initial and the
correct rotation is plotted against the RMSD achieved by each registration method.
method reaches a final pose with RMSD below a given threshold α. A good registration
method should produce large fractions close to 100% for small α. On all test cases, the
deterministic annealing approach performs best, reaching α-recall near 100% for small
α below 1A˚ . Also the MM approach without annealing outperforms ICP, but not as clearly
as DAMM. All approaches face difficulties with target 6HF2, a member of the TIM barrel
fold family. The likely reason for the problems with self-matching 6HF2 lies in the
quasi-symmetry of the structure. Rotations about the barrel axis achieve similar kernel
correlations and RMSDs, which adds to the severeness of the registration problem, because
the chance of getting trapped in a local optimum is increased. Further details on
the performance of the local optimization methods are given in Supplementary Tables S1
and S2.
A systematic discretization of rotation space (Straub et al., 2017; Vakili and Habeck,
2021) allows us to estimate the radius of convergence of the three local registration
algorithms. To do so, we match the TIM barrel structure 6HF2 against itself (no random
permutation or transformation) such that the correct pose is (I,0). Using a tessellation of
SO(3) based on 21792 rotations Rn, we run all three algorithms from initial poses (Rn,0).
The performance of the registration algorithms is measured by the registration error (Gao
and Tedrake, 2019):
error(R, t) =
vuut
1
J
XJ
j=1
∥ˆRRyj + ˆt −Ryj −t∥2 (11)
where (ˆRR, ˆt) is the ground truth pose (here (I,0)). Notice that the registration error (11)
9
Figure 3: Global rigid registration by random search. (A) Center of mass of subunit A of
GroEL projected along the symmetry axis for 1000 poses found by MM. The color encodes
the kernel correlation of the pose (dark blue corresponds to a high kernel correlation, yellow
corresponds to a bad fit). Dashed circles indicate the projected centers of mass of the
subunits in the target (1OEL). (B) Ribbon representation of the top 50 poses found by MM.
The color indicates poses that are superimposed onto the same subunit of the target (chain
A to chain G from 1OEL).
differs from the RMSD defined in Eq. (10), and can be interpreted as the mean squared
deviation between the correctly transformed source and its pose found by a registration
method.
As is evident from Figure 2, the radius of convergence is highest for the MM methods,
confirming our findings from the previous tests. The MM algorithms find the correct pose
even, if the initial rotation has a distance smaller than 0.2 (MM) or 0.4 (DAMM) to the
correct rotation. On the other hand, ICP starts to produce suboptimal fits already at
rotations as close as 0.1. Similar results were obtained for the other target structures
(see Supplementary Figures S3 and S4).
3.2 Performance of global registration by random search
Both the MM algorithms as well as ICP are local optimization methods and suffer from
getting trapped in local minima. A simple strategy to locate the globally best fit is to run
repeated optimizations starting from random initial poses. As a test case we consider
the structure of GroEL which is composed of seven identical subunits exhibiting a 7-
fold cyclic symmetry. The task is to superimpose a single subunit, subunit A, onto the
GroEL ring structure. The kernel correlation of this superposition task has seven global
minima corresponding to fitting one subunit onto any of the seven subunits in the target
10
A
1AJK
2AYH
B
Figure 4: KC-based matching of circularly permuted structures 2AHY and 1AJK. (A) The left
panel shows both structures after registration by maximizing the kernel correlation (Pymol’s
chainbow coloring indicates the order of amino acids in each structure). (B) The right panel
shows the kernel matrix has a heatmap. The row indices correspond to the amino acid sequence
of 2AYH running from bottom (N-terminus) to top (C-terminus). The column indices
correspond to the sequence of 1AJK and run from left (N-terminus) to right (C-terminus).
The brightness of the heatmap is directly proportional to the entries in the kernel matrix.
structure. In addition to the seven global optima, there are a multitude of local minima
corresponding to partial matches between subunits.
To tackle this challenging superposition task, we launch repeated MM runs from random
rotations and translations. The initial translations are uniformly sampled from the
bounding box of the target, the GroEL ring. The initial rotations are uniformly sampled
over SO(3). We first evaluate the grid-based kernel correlation for 105 initial poses and
keep the 1000 best initial poses achieving the highest kernel correlation. For each of
the 1000 best initial poses, we then run the grid-based implementation of MM (see Supplementary
Material D). These computations only take a few seconds on a standard
notebook.
Figure 3A shows center of mass of subunit A (the source) after applying the 1000
poses found by MM. Among the 1000 poses are very close (local) matches of subunit A
onto each of the subunits in the target (see also Fig. 3B). But the large majority of poses
correspond to a poor fit indicated by a low kernel correlation. This means that our global
registration strategy indeed finds all global optima. However, to guarantee that we do not
miss the globally best registration, we have to run MM multiple times from many initial
poses. This is feasible thanks to the speed-up resulting from the grid approximation of
the kernel correlation (see Section 2.3).
11
Figure 5: Docking a crystal structure of exporting CRM1 into a bead model derived from
a SAS curve. The bead model obtained from SASBDB is shown on the left. The right
panel shows the high-resolution structure 4HZK that was docked into the bead model by
maximizing the kernel correlation.
3.3 Comparison of circularly permuted structures
Circular permutation breaks the sequential order of the amino acids and thereby poses a
challenge to standard protein alignment methods. The kernel correlation does not require
a position-to-position correspondence between both structures and is invariant under
shuffling the order of points in each cloud. Therefore, circularly permuted structures can
directly be superimposed and compared with KC-based registration methods.
To illustrate this point, we match the two circularly permuted structures 2AYH and
1AJK using the deterministic annealing approach with σ = 5 A˚ . The aligned structures
are shown in Figure 4A. The correct alignment can be found very rapidly with DAMM. Out
of 10 random initial poses, 3 produced the correct structural fit. At the right (Fig. 4B), we
show the kernel matrix with elements ϕσ(∥xi −Ryj −t∥) as a heatmap. The kernel matrix
clearly delineates corresponding structural regions, which are indicated by “hot” matrix
elements that run parallel to the diagonal and are “folded” due to circular permutation.
3.4 Rigid fitting of bead models from small-angle scattering
Our registration algorithms can also be used to dock structures into bead models derived
from small-angle scattering (SAS) curves. The bead models are obtained from the Small
Angle Scattering Biological Data Bank (SASBDB) (Valentini et al., 2014). The first target
is a bead model of exportin CRM1 derived from a SAS curve (SASBDB code SASDAJ4).
We fit the crystal structure 4HZK into the bead model by maximizing the kernel correlation
with σ = 5 A˚ . Again, we use the deterministic annealing approach to find the pose that
maximizes KC. Figure 5 shows the SAS bead model and a CA trace of the superimposed
crystal structure. The correlation between both point clouds is 75 %. More examples can
be found in Supplementary Figures S5 and S6.
12
A B C
Figure 6: Superposition of low-resolution cryo-EM maps by rigid point cloud registration.
The colors indicate the weight of the particles ranging from blue (high weight) to red (low
weight). (A) Superposition of two bead models of intermediate-resolution maps of the 80S
ribosome (EMD-1067, EMD-1343). (B) Two bead models of the free and nucleotide-bound
structure of axonemal dynein-c (EMD-2155, EMD-2156). (C) Two bead models of human
RNA polymerase II (EMD-2189, EMD-2190) in complex with different RNAs.
13
3.5 Rigid fitting of cryo-EM maps
Next, we use the point-cloud registration methods to align two cryo-EM maps. We superimpose
three pairs of low-resolution maps after converting them to weighted point
clouds. All density maps are downloaded from the EMDataBank (Lawson et al., 2010)
and converted to weighted point clouds by running the DP-means algorithm (Kulis and
Jordan, 2012). We set the desired bead radius to 10 A˚ for the first pair (two 80S ribosome
maps) and to 5 A˚ for the second and third pairs (characterizing a motor protein and RNA
polymerase II). The first pair of medium-resolution maps shows the 80S ribosome at 11.7
A˚ (EMD-1067) and 9.7 A˚ resolution (EMD-1343). DP-means generates weighted point
clouds with 425/666 beads representing EMD-1067/EMD-1343. The second docking
task is to superimpose two low-resolution maps of axonemal dynein-c without and with
nucleotide bound. The low-resolution maps EMD-2155 (apo dynein-c at 19 A˚ resolution)
and EMD-2156 (dynein-c with bound nucleotide at 22 A˚ resolution) are represented by
433 and 405 beads, respectively. The third task is to superimpose bead models derived
from EM maps EMD-2189 and EMD-2190 showing human RNA polymerase II at 25 A˚
resolution in complex with different RNAs. The bead models are composed of 889 and
951 particles. In each of the docking tasks, the kernel bandwidth σ was chosen to be
twice as large as the bead radius.
Figure 6 shows the superpositions obtained with the deterministic annealing approach.
Visual inspection reveals that the 3D superpositions found by DAMM are meaningful.
To quantify this further, we also investigated the correspondence between the negative
log kernel correlation (which is the target function of the MM algorithms) and more
traditional measures for assessing the overlap of two structures or 3D density maps. The
kernel correlation can serve as a surrogate of the cross-correlation coefficient (CCC),
which is typically maximized to superimpose two cryo-EM maps using a voxel representation.
Supplementary Figure S7 shows that there is high correlation between both
metrics. An advantage of the kernel correlation compared to the CCC is that it can be
evaluated very efficiently and does not require the interpolation of the moving cryo-EM
structure over a voxel grid. Similarly, we also see a high agreement between −log κ and
the RMSD as defined in Eq. (10).
3.6 Rigid fitting of subunits into cryo-EM density maps of symmetric
assemblies
Finally, we use KC-based point cloud registration to dock a high-resolution structure of a
single subunit into a cryo-EM map of a symmetric assembly. As is shown in the Supplementary
Material, the kernel correlation as well as the majorization-minimization strategy
for finding the best superposition can readily be adapted to the symmetric case.
We demonstrate the ability to dock structures into symmetric assemblies for the highresolution
map of the capsaicin receptor TRPV1 (EMD-5778). This assembly exhibits a
four-fold cyclic symmetry and served as a target for rigidly fitting a single subunit into the
14
Figure 7: Rigid fitting of an atomic structure of a subunit into a high-resolution map of the
symmetric channel TRPV1. Left: Cryo-EM map EMD-5778. Middle left: Bead model representing
the cryo-EM map where the colors indicate the weight of particles. Middle right:
Docked structure of the subunit and symmetry mates shown as bead models. Right: Docked
high-resolution structure.
map. The map and the symmetry operators were downloaded from the EMDataBank.
We converted the map to a weighted point cloud by applying DP-means using a bead
radius of 5 A˚ . The modeled structure of a single subunit (PDB code 3J5P) was docked
into the assembly by maximizing the symmetrized kernel correlation.
Figure S10 shows the cryo-EM map of the assembly and its point cloud representation
next to the assembly predicted by fitting the structure of the subunit into the assembly.
Visual inspection confirms that the subunit has been docked correctly into the point cloud
representing the assembly. The correlation between both point clouds is 65 %. More
examples of rigid fits into symmetric assemblies are presented in Supplementary Figure
S8.
4 Conclusion
3D superposition of biomolecular structure is a common task in structural biology that is
typically solved by specialized algorithms and software that depend on the representation
of a 3D structure. In this article, we address 3D fitting problems within a common
framework based on the registration of weighted point clouds. As a measure of similarity,
we use the kernel correlation, and introduce iterative algorithms for optimizing it so as to
superimpose two point clouds.
An advantage of the kernel correlation over RMSD-based approaches is that KC does
not require a point-to-point correspondence. This advantage comes at the cost of having
to deal with an objective function that exhibits multiple optima and is therefore more
difficult to optimize than the standard RMSD or its modified versions. Local point-cloud
registration algorithms therefore risk to get trapped in local optima. To overcome these
challenges, we introduced an iterative MM algorithm and its annealed version, which
both have a larger radius of convergence and thereby a lower chance of getting trapped
in suboptima than the commonly used ICP method. Due to the generality of the representation,
our rigid registration approach can be applied to various 3D fitting problems
15
including the comparison of circularly permuted structures or the superposition of bead
models and density maps from cryo-EM.
There is still room to improve the efficiency of the registration algorithm. Its current
implementation is not fast enough for large-scale similarity searches based on point
clouds. The computation time to evaluate the kernel correlation scales with the size of
both point clouds. Therefore, to improve the search over all rigid transformation, we plan
to pursue a multiscale approach based on a hierarchical representation of point clouds.
Coarser representations would involve a smaller number of points thereby allowing us
to evaluate the kernel correlation more rapidly. Combined with a global grid search, a
multiscale approach should enable us to exhaustively scan all rigid transformations and
further reduce the chance to miss the global optimum. Another interesting direction is
to fit multiple subunits into a point cloud representing an assembly, and to fit 3D point
clouds against 2D point clouds derived from projection images obtained with electron
microscopy or tomography as well as other imaging methods.
Funding
MH, AK and NV gratefully acknowledges funding by the Carl Zeiss Foundation within the
program “CZS Stiftungsprofessuren”. MH and NV acknowledge funding from the German
Research Foundation (DFG) within SFB 860 subproject B09. MH and AK are grateful for
the support of the DFG within project 432680300 - SFB 1456 subprojects A05.
References
Berman, H. M.,Westbrook, J., Feng, Z., Gilliland, G., Bhat, T. N.,Weissig, H., Shindyalov,
I. N., and Bourne, P. E. (2000). The Protein Data Bank. Nucleic Acids Res., 28, 235–
242.
Besl, P. and McKay, N. D. (1992). A method for registration of 3-d shapes. IEEE Transactions
on Pattern Analysis & Machine Intelligence, 14(2), 239–256.
Chen, Y. and Medioni, G. (1992). Object modelling by registration of multiple range
images. Image and vision computing, 10(3), 145–155.
Damm, K. L. and Carlson, H. A. (2006). Gaussian-weighted rmsd superposition of proteins:
a structural comparison for flexible proteins and predicted protein structures.
Biophys J, 90(12), 4558–4573.
Gao, W. and Tedrake, R. (2019). Filterreg: Robust and efficient probabilistic point-set
registration using gaussian filter and twist parameterization. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11095–
11104.
16
Higham, N. J. (1989). Matrix nearness problems and applications. In M. J. C. Gover
and S. Barnett, editors, Applications of Matrix Theory, pages 1–27. Oxford University
Press.
Hirsch, M. and Habeck, M. (2008). Mixture models for protein structure ensembles.
Bioinformatics, 24, 2184–2192.
Hunter, D. R. and Lange, K. (2004). A tutorial on mm algorithms. The American Statistician,
58(1), 30–37.
Kabsch, W. (1976). A solution for the best rotation to relate two sets of vectors. Acta
Crystallographica, A32, 922–923.
Kawabata, T. (2008). Multiple subunit fitting into a low-resolution density map of a macromolecular
complex using a gaussian mixture model. Biophys. J., 95, 4643–4658.
Kulis, B. and Jordan, M. I. (2012). Revisiting k-means: New algorithms via bayesian
nonparametrics. In J. Langford and J. Pineau, editors, Proceedings of the 29th International
Conference on Machine Learning (ICML-12), pages 513–520, New York, NY,
USA. ACM.
Lawson, C. L., Baker, M. L., Best, C., Bi, C., Dougherty, M., Feng, P., van Ginkel, G.,
Devkota, B., Lagerstedt, I., Ludtke, S. J., Newman, R. H., Oldfield, T. J., Rees, I.,
Sahni, G., Sala, R., Velankar, S., Warren, J., Westbrook, J. D., Henrick, K., Kleywegt,
G. J., Berman, H. M., and Chiu, W. (2010). EMDataBank.org: unified data resource
for CryoEM. Nucleic Acids Research, 39(suppl 1), D456–D464.
Mechelke, M. and Habeck, M. (2010). Robust probabilistic superposition and comparison
of protein structures. BMC Bioinformatics, 11, 363.
Ritchie, D. W. (2016). Calculating and scoring high quality multiple flexible protein structure
alignments. Bioinformatics, 32(17), 2650–2658.
Rose, K., Gurewitz, E., and Fox, G. (1990). A deterministic annealing approach to clustering.
Pattern Recognition Letters, 11(9), 589–594.
Straub, J., Campbell, T., How, J. P., and Fisher, J. W. (2017). Efficient Global Point
Cloud Alignment Using Bayesian Nonparametric Mixtures. In 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), volume 00, pages 2403–2412.
Suzuki, H., Kawabata, T., and Nakamura, H. (2016). Omokage search: shape similarity
search service for biomolecular structures in both the pdb and emdb. Bioinformatics,
32(4), 619–620.
Theobald, D. L. and Wuttke, D. S. (2006). Empirical Bayes hierarchical models for regularizing
maximum likelihood estimation in the matrix Gaussian Procrustes problem.
Proc. Nat. Acad. Sci., 103, 18521–18527.
17
Tsin, Y. and Kanade, T. (2004). A correlation-based approach to robust point set registration.
In European conference on computer vision, pages 558–569. Springer.
Vakili, N. and Habeck, M. (2021). Bayesian random tomography of particle systems.
Frontiers in Molecular Biosciences, 8, 399.
Valentini, E., Kikhney, A. G., Previtali, G., Jeffries, C. M., and Svergun, D. I. (2014). SASBDB,
a repository for biological small-angle scattering data. Nucleic Acids Research,
43(D1), D357–D363.
Villa, E. and Lasker, K. (2014). Finding the right fit: chiseling structures out of cryoelectron
microscopy maps. Curr. Opin. Struct. Biol., 25, 118–125.
Zhou, Q.-Y., Park, J., and Koltun, V. (2016). Fast global registration. In European conference
on computer vision, pages 766–782. Springer.
18
A Algorithms
This section lists all algorithms presented in the paper.
A.1 MM algorithm to locally minimize the negative log kernel
correlation
To optimize the kernel correlation locally, we run the iterations (with iteration index n used
as upperscript) starting from an initial pose (R(0), t(0)):
w(n)
ij ←
ϕσ(∥xi −R(n)yj −t(n)∥)
P
i′j′ qi′pj′ϕσ(∥xi′ −R(n)yj′ −t(n)∥)
(12)
(R(n+1), t(n+1)) ← argmin
R∈SO(3), t∈R3
u(n)(R, t) (13)
where
u(n)(R, t) =
1
2
X
ij
qipjw(n)
ij ∥xi −Ryj −t∥2 (14)
is an upper bound (up to a constant) of −log κ.
A.2 Deterministic annealing during MM
In deterministic annealing, we decrease the bandwidth σ during the MM iterations according
to a schedule σ(0) > σ(1) ≥ σ(2) > ...:
w(n)
ij ←
ϕσ(n) (∥xi −R(n)yj − t(n)∥)
P
i′j′ qi′pj′ϕσ(n) (∥xi′ −R(n)yj′ −t(n)∥)
(15)
(R(n+1), t(n+1)) ← argmin
R∈SO(3), t∈R3
u(n)(R, t) (16)
A.3 Iterative closest point (ICP)
Iterative closest point (ICP) is among the most commonly used approaches for rigid registration
of point clouds. ICP iterates over updating a point-to-point correspondence i(j)
between points in the target (X,q) and the source (Y,p), and updating the rigid transformation
(R, t):
i(n)(j) = argmin
i∈{1,...,I}
∥xi −R(n)yj −t(n)∥ (17)
(R(n+1), t(n+1)) ← argmin
R∈SO(3), t∈R3
X
j
∥xi(n)(j) −Ryj −t∥2 (18)
19
A.4 Minimization of the upper bound
To minimize u(n), we use a variant of the Kabsch algorithm. The gradient of the upper
bound with respect to the translation is
∇tu(n)(R, t) = t −
X
ij
qipjw(n)
ij (xi −Ryj ) = t −
X
ij
qipjw(n)
ij xi
| {z }
x
+R
X
ij
qipjw(n)
ij yj
| {z }
y
(19)
Setting ∇tu(n) to zero and solving for t yields the optimal translation as a function of the
rotation:
ˆt = x −Ry (20)
Plugging this estimator into u(n) yields an upper bound that depends only on R:
u(n)(R, ˆtt) =
1
2
X
ij
qipjw(n)
ij ∥(xi −x) −R(yj −y)∥2 (21)
=
1
2
X
ij
qipjw(n)
ij

∥xi −x∥2 + ∥yj −y∥2

− tr
X
ij
qipjw(n)
ij (yj −y)(xi −x)T
| {z }
ST
R

(22)
To minimize u(n) we have to maximize tr(STR) which can be achieved by computing a
singular value decomposition of the 3 × 3 matrix S as in the standard Kabsch algorithm.
A.5 Data structures for fast evaluation of the kernel correlation
We use several approximations to speed up the evaluation of −log κ.
A.5.1 Distance cutoff
The support of the RBF kernel ϕσ is the entire positive real axis, but for r > 3σ the
contributions are negligible. Therefore, we set
ϕσ(r ) =
 
1
(2πσ2)3/2 exp
n
− r 2
2σ2
o
0 ≤ r < 3σ
0 r ≥ 3σ
(23)
This approximation reduces the evaluation of ∥xi −Ryj −t∥ to nearest neighbors inside
a ball of radius 3σ. There exist efficient data structures for nearest-neighbor searches
such as k-d trees, ball trees and neighbor lists.
A.5.2 Gridding
The kernel density estimates (KDEs) induced by both point clouds are
qσ(x) =
XI
i=1
qi ϕσ(∥x −xi∥), pσ(x) =
XJ
j=1
pj ϕσ(∥x −yj∥) (24)
20
We can interpret the kernel correlation as the scalar product of two KDEs:
κ(R, t) = ⟨qσ1 , pσ2 (RT (· −t))⟩ (25)
where the bandwidths of the KDEs need to satisfy σ2 = σ2
1 + σ2
2. We can use a regular
cubic grid
G =
n
x0 + Δ(n1, n2, n3)T | n1 ∈ [N1], n2 ∈ [N2], n3 ∈ [N3]
o
(26)
to approximate the integral in the scalar product. Here, [N] := {0, 1, ... ,N − 1} for some
natural number N ∈ N. The scalar Δ > 0 is the grid spacing and x0 ∈ R3 the grid origin.
We then have
κ(R, t) =
Z
qσ1 (z) pσ2 (RT (z −t)) dz ≈
X
z∈G
qσ1 (z) pσ2 (z) . (27)
We now choose σ1 = σ (bandwidth of the fixed target) and σ2 = 0 (bandwidth of the
moving source), then the source is represented by a sum of delta peaks
p0(x) =
XJ
j=1
pj δ(∥x −yj∥) .
In practice, the source density p0 is obtained by the following algorithm:
• For a given pose (R, t), transform the source yj 7→ Ryj + t.
• Compute the multi-index of the grid cell that contains the transformed point yj :
nj = round((Ryj + t −x0)/Δ) ∈ N3
• Map the multi-index nj to a flat grid index
nj = N2N3nj1 + N3nj2 + nj3
enumerating all grid cells and add the weight pj of source point yj to grid cell nj .
The approximate kernel correlation can then be computed by
κ(R, t) ≈
X
x∈G
qσ(x) p0(RT (x −t)) =
X
k
qkpk (28)
where {qσ(x)}x∈G = (q1, ... , q|G|) is a size |G| vector that only needs to be computed once
and pk is a sparse binary vector that can be computed very rapidly for a new pose. To
compute pk , the transformed source Ryj + t is mapped to the grid G by applying the
following steps:
1. zj ←Ryj + t (transform source)
2. zj ←zj −x0 (subtract grid origin)
3. zj ← round(zj/Δ) (map to multi-index)
This runs in O(J).
21
B Computation times for fast evaluation of the kernel
correlation
The kernel correlation is evaluated on two large point clouds derived from PDB files
5M52 and 5M5P where now each listed atom (not only carbon alphas) defines a point.
The target point cloud comprises 34512 and the source 67309 points. The evaluation
of the exact kernel correlation without a hard distance cutoff on ϕ requires prohibitively
long computation times and/or a large working memory (our default implementation of KC
computes the full distance matrix between all pairs of points in the target and source). As
a reference to compare different implementation of the kernel correlation, we therefore
use a version based on a kernel density estimate (KDE) from scikit-learn. The KDEbased
implementation took 650 ± 19 sec. per pose for σ = 3 A˚ on a i7 processor (1.8
GHz oct-core using a single thread only) on 10 random poses. By using the implementation
described in section 2.3, the time for computing the kernel correlation is sped up
significantly by 1 to 3 orders of magnitude as shown in the figure below. The fast KC
implementations are based on approximations (3σ cutoff and/or discretization), which result
in approximate KC values. However, the accuracy of the approximate KC values is
quite high as indicates by the Pearson correlation coefficients approximate and exact KC
values: 100.00 % (k-d tree), 100.00 % (ball tree), and 99.98% (cubic grid).
kd-tree ball tree cubic grid
10 1
100
101
computation time [s]
Figure S1: Computation times for evaluating the kernel correlation with an implementation
using k-d trees, ball trees, and a cubic grid.
22
C Iterative majorization-minimization (MM)
The figure below illustrates the majorization-minimization (MM) approach used in this paper
to minimize the negative log kernel correlation −log κ. Instead of minimizing −log κ
directly over all rotational and translational degrees of freedom, our MM algorithms minimize
an upper bound u(n) detailed in Eq. (14) (also see Eq. (7) in the main article). The
progression of the MM iterations is shown for a self-matching task where PDB structure
6JC2 is fitted against itself. As is evidenced by the plot, the upper bound u(n) is quite tight
and becomes even tighter in the course of the MM iterations as n increases.
0 10 20 30 40 50
iteration n
7.5
7.0
6.5
6.0
log
6JC2
upper bound u(n)
log
min{ log }
Figure S2: Evolution of the negative log kernel correlation −log κ, our objective function to
superimpose two weighted point clouds, during the MM iterations. Instead of −log κ itself,
each iteration minimizes the upper bound u(n) shown in yellow.
23
D Majorization-minimization (MM) of grid-based kernel
correlation
The MM update also benefit from a speed up based on approximating the kernel correlation
on a regular cubic grid. The weights of the current pose (R, t) are
wij =
ϕσ(∥xi −Ryj −t∥) P
i′j′ ϕσ(∥xi′ −Ryj′ −t∥)
.
The grid approximation of the Gaussian kernel is
ϕσ(∥xi −Ryj −t∥) ≈
X
zk∈G
ϕσ(∥xi −zk∥)δ(∥zk −Ryj −t∥) =
X
k
ϕik δjk
where δ is the delta function and G a regular cubic grid whose grid cells are centered at
zk and indexed by the flat index k. The kernel matrix ϕik does not change in the course
of the MM procedure.
In the MM iterations, we need to compute the weighted means x and y of the target
and the source. We have
x =
X
ij
wijqipjxi ≈
P
ijk ϕik δjkqipjxi P
ijk ϕik δjkqipj
=
P
k
􀀀P
i ϕikqixi
 P
j pjδjk

P
k
􀀀P
i qiϕik
 P
j pjδjk
 =
P
Pk x˜ kp˜k
k ˜qk ˜pk
(29)
where we defined ˜qk =
P
i qiϕik (the target KDE evaluated on the grid G), ˜pk =
P
j pjδjk
(the weighted sum of delta peaks located at the transformed source positions Ryj + t
evaluated on G via rounding), and x˜ k =
P
i qiϕikxi . All q˜k and x˜ k can be computed before
launching the MM iterations and will stay constant in the course of the iterations. The
gridded sum of delta functions ˜pk has to be recomputed each time the source adopts
a new pose, but computation of ˜pk is very fast because it can be done by rounding the
coordinates of the source points to grid cells. Moreover, ˜pk is a sparse array and sums
involving ˜pk can be restricted to those grid cells that are occupied by a source point.
Similarly, we can show that
y =
X
ij
wijqipjyj ≈
P
Pk y˜ kq˜k
k ˜qk ˜pk
(30)
with y˜ k =
P
j pjδjkyj which is a sparse array of 3D vectors. Estimation of the optimal
rotation is then achieved by computing the SVD of the matrix
S =
X
ij
qipjϕσ(∥xi −Ryj −t∥)(xi −x)(yj −y)T (31)
≈
X
k
X
i
qiϕik (xi −x)
X
j
pjδjk (yj −y)
T
(32)
=
X
k
(x˜ k − q˜kx)(y˜ k − p˜ky)T . (33)
Again, since p˜k and y˜ k are sparse, the computation of S is very fast.
24
E Self-match benchmark with random initial rotation
and translation
Both in terms of the correlation (which is proportional to the objective function of MM and
DAMM) as well as the RMSD (which is the objective function of ICP), the deterministic
annealing approach performs best, reaching correlations near 100% and RMSDs close
to zero for most test cases:
6JC2 6HF2 1OEL 5G5D 6R4S
MM 1.00±0.01 0.96 ± 0.04 0.96 ± 0.08 0.99 ± 0.01 0.99 ± 0.03
DAMM 1.00±0.00 0.99±0.03 1.00±0.02 1.00±0.00 1.00±0.01
ICP 0.99 ± 0.03 0.92 ± 0.05 0.92 ± 0.11 0.98 ± 0.02 0.98 ± 0.05
Table S1: Average correlation coefficient.
6JC2 6HF2 1OEL 5G5D 6R4S
MM 0.21 ± 0.57 2.14 ± 1.49 1.36 ± 1.80 0.64 ± 1.03 0.52 ± 1.12
DAMM 0.00±0.02 0.96±1.22 0.07±0.49 0.19±0.34 0.04±0.36
ICP 0.28 ± 0.96 2.76 ± 1.80 1.96 ± 2.35 1.02 ± 1.40 0.48 ± 1.34
Table S2: Average RMSD in A˚ .
Also the MM approach without annealing outperforms ICP, but not as clearly as
DAMM. Nevertheless, all approaches face difficulties with target 6HF2, a member of
the TIM barrel fold family. These difficulties can be overcome by using a larger number of
initial poses. When we increased the number of random initial poses from 10 to 50, the
average correlations improved to 99.9% (MM), 100.0% (DAMM), and 98.5% (ICP), as do
the average RMSDs: 0.2 A˚ (MM), 0.1 A˚ (DAMM), and 0.6 A˚ (ICP).
25
F Radius of convergence of iterative registration
methods
In addition to the example shown in Figure 2 of the main manuscript, we also assessed
the radius of convergence of three registration methods (ICP: iterative closest point; MM:
iterative majorization-minimization; DAMM: MM with deterministic annealing) using four
other test cases. The setup is the same as described in the main paper. In all tests, the
MM methods have a larger radius of convergence than ICP (see Fig. S3 and Fig. S4).
Figure S3: Radius of convergence. Distance between initial and true rotation versus the
RMSD of the final pose generated by the registration methods: MM (red), DAMM (blue), ICP
(yellow).
26
Figure S4: Radius of convergence. RMSD of initial pose versus RMSD of the final pose
generated by the registration methods: MM (red), DAMM (blue), ICP (yellow).
27
In most examples, we see the emergence of a second dominant cluster of solutions with
high RMSD values. These registrations correspond to an alternative 3D superpositions
due to a quasi-symmetry of the point cloud. For example, in case of 6JC2 we are dealing
with a heterodimer where the two monomers are very similar to each other. The bad fit
with an RMSD of 41.6 A˚ achieves a correlation 91% and is shown in Fig. S5(a). In case
of 5G5D, we are dealing with a member of the Carbohydrate-binding domain superfamily,
which also exhibits a quasi-symmetry. If we ignore the sequence information and only
look at the spatial arrangement of CA atoms, the bad fit with an RMSD of 28.2 A˚ achieves
a correlation of 97% and is shown in Fig. S5(b).
(a) 6JC2
(b) 5G5D
Figure S5: Left: target point cloud. Right: bad pose with a good correlation but high RMSD.
28
G Self-match benchmark with random initial rotation
and grid search of the translation
The self-matching benchmark (subsection 3.1.1 of the main article) was modified as follows.
Instead of choosing the initial translation randomly, it was optimized by maximizing
the kernel correlation over a regular cubic grid. The resulting average correlation values
and RMSDs can found in the following figure:
90
95
100
correlation [%]
6JC2 6HF2 1OEL 5G5D 6R4S
MM
DAMM
ICP
0
1
2
3
RMSD [Å]
MM
DAMM
ICP
MM
DAMM
ICP
MM
DAMM
ICP
MM
DAMM
ICP
Figure S6: Testing the impact of using an initial translation that is optimized over a cubic grid
of cell size 1 A˚ . A PDB structure (indicated in panel titles) is fitted against a permuted and
randomly transformed version of itself. The top row shows the correlation coefficient (ratio of
actual kernel correlation and maximum achievable kernel correlation) obtained when starting
local optimization runs from 10 random initial rotations (and optimized translations). The
bottom row shows the RMSD (defined in equation 7 of the main paper) of corresponding
points after striking the estimated pose.
29
H Fitting of atomic structures into bead models derived
from small-angle scattering curves
The main article illustrates the ability to fit high-resolution structures into bead models
from small-angle scattering (SAS) curves for an exportin structure. Here, we demonstrate
this for two additional examples. The first example also involves exportin CRM1. We fitted
a bead model of free CRM1 (SASDAJ4) against CRM1 RanGTP (SASDAK4). The figure
S7 shows the final superposition found by maximizing the kernel correlation with σ = 5
A˚ . The correlation of the final fit is 80.3%.
Figure S7: 3D superposition of SASDAK4 (CRM1 RanGTP, shown on the right) onto SASDAJ4
(free CRM1, shown on the left).
The second example involves fitting a bead model of Human Chromatin Remodeler
CHD4 (SASBDB code SASDAA5) against two other SASBDB structures: the apo form of
full length ObgE (SASDBS6) and mitochondrial heat shock protein 70 (SASDBY6). The
superposition is shown in figure S8.
30
Figure S8: Point cloud registration onto SASDAA5 (grey top). Bead models SASDBS6 (red)
and SASDBY6 (blue) were fitted onto SASDAA5 by maximizing the kernel correlation using
DAMM.
31
I Kernel correlation as a proxy for the cross-correlation
coefficient and the RMSD
By construction, the kernel correlation is highly related to the cross-correlation coefficient
(CCC) that is often used to measure the overlap of two cryo-EM density maps
represented on voxel grids. This is demonstrated in the figure below for one of the cryo-
EM docking targets discussed in the main text (superposition of two RNA polymerase II
structures). We observe a high correlation between the negative log kernel correlation
(which is optimized by the MM algorithms introduced in Methods) and CCC between the
target map and the transformed map. Therefore, by minimizing −log κ we effectively
maximize the CCC between the two density maps.
A high correlation is also observed between the RMSD (as defined in equation 7 of
the main article) and the negative log kernel correlation. The RMSD is optimized by ICP.
13.1 13.0 12.9
logKC
0
20
40
60
80
CCC [%]
13.1 13.0 12.9
logKC
6
8
10
12
RMSD [Å]
Figure S9: Kernel correlation as a proxy for RMSD and cross-correlation coefficient (CCC).
Left: High correlation between −log κ and CCC. Right: High correlation between −log κ and
the RMSD (see equation 7 in main manuscript.)
32
J Docking the high-resolution structure of a subunit
into a cryo-EM map of a symmetric assembly
The first point cloud, (X,q), represents the full assembly and is derived, for example,
from a cryo-EM map. The second point cloud, (Y,p), represents the subunit that will
be docked into the full assembly. We assume that the assembly is symmetric and the
symmetry mates can be generated from a single subunit by the action of C rigid transformations
{(Rk , tk )}Ck
=1. The subunit needs to be transformed by an unknown rigid transformation
(R, t) such that the overlap between the target and the full model structure is
as large as possible. The coordinates of the k-th subunit after rigid transformation are:
y′
jk = Rk (Ryj + t) + tk
The kernel correlation between the point cloud representing the assembly and the structure
of the assembly built by applying the symmetry operators is:
κsym(R, t) =
XM
i=1
XN
j=1
XC
k=1
qipjϕσ(∥xi −Rk (Ryj + t) −tk∥)
We can rewrite the kernel correlation of a symmetric assembly:
κsym(R, t) =
XM
i=1
XN
j=1
XC
k=1
qipjϕσ(∥RTk
(xi −tk ) −Ryj −t∥)
Upper bound:
−log κsym(R, t) = −log


XM
i=1
XN
j=1
XC
k=1
qipjϕσ(∥xi −Rk (Ryj + t) −tk∥)


= −log


X
ijk
qipjwijk
ϕσ(∥xi −Rk (Ryj + t) −tk∥)
wijk


≤
1
2σ2
X
ijk
qipjwijk ∥xi −Rk (Ryj + t) −tk∥2 + const.
where the weights
wijk ∝ ϕσ(∥xi −Rk (Ryj + t) −tk∥)
are normalized such that
P
ijk qipjwijk = 1.
More examples of 3D fitting into symmetric assemblies by maximizing κsym are shown
in Fig. S10.
33
(a) EMD-6422
(b) EMD-5995
(c) EMD-6000
Figure S10: Rigid docking of a subunit into a symmetric assembly. EMD-6422: GroEL, D7
symmetry. EMD-5995: beta-galactosidase, D2 symmetry. EMD-6000: Brome mosaic virus.
In each row, the point cloud on the left shows the particle representation of the cryo-EM
map of the assembly obtained by running DP-means with a particle radius of 5 A˚ . The colors
indicate the weight of the particles. The middle panel shows the fitted structure of the subunit
that was also coarse-grained by running DP-means. The structure in blue is the subunit; all
other particles were generated on the fly by applying the symmetry operators. The right
panel is the high-resolution structure of the full assembly obtained by transforming the highresolution
structure of the subunit rigidly by using the estimated pose and by generating the
symmetry mates by applying the symmetry operators.
34